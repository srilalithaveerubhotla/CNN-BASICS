{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16 pytorch cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilalithaveerubhotla/CNN-BASICS/blob/master/vgg16_pytorch_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GHTF_ausyt8",
        "colab_type": "text"
      },
      "source": [
        "# VGG16 pytorch scratch code on cifar100 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_IhbnPEsCGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libraries\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWnJc8wMqnYw",
        "colab_type": "code",
        "outputId": "9d36a9cd-7e04-455d-f573-6e029c0f6973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# downloading CIFAR100 dataset\n",
        "# transforming the PIL Image to tensors\n",
        "train = torchvision.datasets.CIFAR100(root = \"./data\", train=True, download = True, transform = transforms.ToTensor())\n",
        "\n",
        "#loading the training data from trainset\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=4, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaD8ZN9as1TI",
        "colab_type": "text"
      },
      "source": [
        "## VGG16 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGuCWBiliCWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference: https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/vgg.py\n",
        "\n",
        "cfg = {\n",
        "    'A' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M']\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_class=100):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.classifier(output)\n",
        "    \n",
        "        return output\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "\n",
        "    input_channel = 3\n",
        "    for l in cfg:\n",
        "        if l == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            continue\n",
        "\n",
        "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
        "\n",
        "        if batch_norm:\n",
        "            layers += [nn.BatchNorm2d(l)]\n",
        "        \n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        input_channel = l\n",
        "    \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def vgg16_bn():\n",
        "    return VGG(make_layers(cfg['A'], batch_norm=True))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQrT4_UQrmIv",
        "colab_type": "code",
        "outputId": "fd05d5b3-5559-486f-90a2-e4e21b371314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "source": [
        "net = vgg16_bn()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6j_lwpsrs4t",
        "colab_type": "code",
        "outputId": "ef722900-47fe-4884-c952-3fdfb9f8d688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# view the training data\n",
        "\n",
        "#iterating into the data\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# view the shape of 4 images\n",
        "print(images.shape) \n",
        "\n",
        "# view the shape of 1 image\n",
        "print(images[1].shape) \n",
        "\n",
        "# view the label of the first image\n",
        "print(labels[1].item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([3, 32, 32])\n",
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSlbKFyYr09M",
        "colab_type": "code",
        "outputId": "7d34c526-791d-4459-caff-6fa49e964549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "#taking the first image from batch of 4 images\n",
        "\n",
        "img = images[0]\n",
        "print(type(img))\n",
        "\n",
        "#convert the tensor to numpy for displaying the image\n",
        "npimg = img.numpy()\n",
        "print(npimg.shape)\n",
        "\n",
        "#for displaying the image, shape of the image should be height * width * channels\n",
        "npimg = np.transpose(npimg, (1, 2, 0))\n",
        "print(npimg.shape)\n",
        "\n",
        "plt.figure(figsize = (2,2))\n",
        "plt.imshow(np.squeeze(npimg))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "(3, 32, 32)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9PdmGkTscn5",
        "colab_type": "code",
        "outputId": "be92cc12-1bbf-4f98-e4bc-cdf3a61f682f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Training VGG16 \n",
        "\n",
        "#increase the batch size\n",
        "batch_size = 128\n",
        "\n",
        "#download the data again and set the train, test loader with different batch size\n",
        "train = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpvCXvvCsll1",
        "colab_type": "code",
        "outputId": "d00ec9d3-7545-48ca-a264-775cd24490cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#reference a variable to gpu card to make the training faster\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ6KXyTTsr3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the model object and move it to GPU\n",
        "net = vgg16_bn().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li0zewLettZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method to calculate the accuracy on a gpu\n",
        "def evaluate(dataloader):\n",
        "    total, correct = 0, 0\n",
        "    \n",
        "    #keeping the network in evaluation mode\n",
        "    net.eval()\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        #moving the inputs and labels to gpu\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtc7gGTlr9UF",
        "colab_type": "code",
        "outputId": "b8128454-0b36-489e-a068-fe705d606d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "%%time\n",
        "loss_arr = []\n",
        "loss_epoch_arr = []\n",
        "max_epochs = 1\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    #iterate through all the batches in each epoch\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "        #keeping the network in training mode\n",
        "        net.train()\n",
        "    \n",
        "        inputs, labels = data\n",
        "        #moving the input and labels to gpu\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        #clear the gradients\n",
        "        opt.zero_grad()\n",
        "        #forward pass\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        #backward pass\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        loss_arr.append(loss.item())\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluate(testloader), evaluate(trainloader)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/1, Test acc: 3.29, Train acc: 3.44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 18s, sys: 1min 20s, total: 3min 38s\n",
            "Wall time: 3min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv--FMkysh-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}